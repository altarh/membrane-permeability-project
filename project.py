# -*- coding: utf-8 -*-

"""MLCB Homework 2: Post hoc explanations and Graph Neural Networks .ipynb

Automatically generated by Colab.

Original file is located at
https://colab.research.google.com/drive/175K_tqNhHlc8ZiFXUEqIqbI2vEbPX3A_

# Advanced Topics in Machine Learning for Computational Biology

## Homework 2: Antimicrobial Property prediction with tree ensembles and graph neural networks

Figure and data from: A Deep Learning Approach to Antimicrobial Discovery, Stokes et al. Cell 2020.

## Download data & install packages
"""
import torch

# NOT NEEDED - original homework data download
#!wget https://github.com/jertubiana/jertubiana.github.io/raw/master/misc/MLCB_2024_HW2_Data.zip
#!unzip /content/MLCB_2024_HW2_Data.zip
#!pip install matplotlib seaborn shap torch_geometric rdkit

"""# Package & data loading"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy.sparse import csr_array
from scipy.sparse.csgraph import connected_components
from sklearn.model_selection import GroupShuffleSplit, StratifiedGroupKFold

from data_loading import read_file_and_add_Class_Label
from mol_properties import get_features_and_morgan_fingerprints
from mol_to_GNN import molecule_to_graph

try:
    from IPython.display import display
except ImportError:
    def display(obj):
        print(obj)  # Fallback to print

# table_first_round_molecules   =  pd.read_excel( '/content/MLCB_2024_HW2_Data/training_table.xlsx',skiprows=1,sheet_name='S1B')
table_first_round_molecules = read_file_and_add_Class_Label('CycPeptMPDB_First30.csv')

"""# Part 0: Parsing the data into Tabular Machine Learning format using the RDKIT package

In this section we:
- Convert each SMILE into a RDKIT Molecule class instance, which has many useful methods.

- Calculate various physio-chemical features for each molecule using RDKIT pre-provided functions. Example of features include number of atoms and bonds of each type, number of hydrogen bond donor and acceptors, etc.

"""

# SMILES is a string-based representation of molecules.
# first_round_molecules_smiles = table_first_round_molecules['SMILES']
# evaluation_molecules_smiles = table_evaluation_molecules['SMILES']

# We first turn each molecule into an instance of the RDKIT molecule.
# first_round_molecules_rdkit = [Chem.MolFromSmiles(smiles) for smiles in first_round_molecules_smiles]
# evaluation_molecules_rdkit = [Chem.MolFromSmiles(smiles) for smiles in evaluation_molecules_smiles]

# Discard examples for which conversion failed.
# first_round_molecules_success = [i for i in range(len(first_round_molecules_rdkit)) if first_round_molecules_rdkit[i] is not None]
# evaluation_molecules_success = [i for i in range(len(evaluation_molecules_rdkit)) if evaluation_molecules_rdkit[i] is not None]

# print(f'Molecule construction suceeded for {len(first_round_molecules_success)}/{len(first_round_molecules_rdkit)} examples in the first round dataset')
# if len(first_round_molecules_success) < len(first_round_molecules_rdkit):
#     print(f'Molecule construction failed for { len(first_round_molecules_rdkit)-len(first_round_molecules_success) }/{len(first_round_molecules_rdkit)} examples in the first round dataset')
# print(f'Molecule construction failed for {len(evaluation_molecules_rdkit) - len(evaluation_molecules_success)}/{len(evaluation_molecules_rdkit)} examples in the evaluation dataset')

# table_first_round_molecules = table_first_round_molecules.iloc[first_round_molecules_success].reset_index()
# table_evaluation_molecules = table_evaluation_molecules.iloc[evaluation_molecules_success].reset_index()

# first_round_molecules_rdkit = [mol for mol in first_round_molecules_rdkit if mol is not None]
# evaluation_molecules_rdkit = [mol for mol in evaluation_molecules_rdkit if mol is not None]


# print('Extracting chemical features/descriptors for each molecule...')
# features_first_round_molecules = extract_chemical_features(first_round_molecules_rdkit)
# print('Done.')
# features_first_round_molecules.index = table_first_round_molecules['Name']

# features_evaluation_molecules = extract_chemical_features(evaluation_molecules_rdkit)
# features_evaluation_molecules.index = table_evaluation_molecules['Name']

"""# Part I: Exploratory Data Analysis

1.	Display, as a scatter plot, the distribution of the number of atoms and covalent bonds per molecule. Color by the measured  class. Is there a relationship between molecule size and activity?
"""



"""2.	For each of the following five features:
*   Octanol-water partition coefficient
*   Molecular weight
*   Number of hydrogen bond donors
*   Number of hydrogen bond acceptors
*   Number of aromatic rings


Display the histogram of the feature value, for each of the two classes. Which feature(s) have the strongest discriminative power?

"""



"""# Part II: Data Partition

Our training data is NOT independently distributed because many known antimicrobial molecules were obtained by small modifications of previously known molecules. Indeed, similar molecules often have similar chemical activity. We thus need to partition the data with grouped splits.


Specifically, our goal is to build a model that can generalize well to unseen molecules. To this end, we want to make sure that our molecules from the train, validation and test are “dissimilar enough”.


We will use the Tanimoto similarity, a custom metric for calculating similarity between molecules (from 0 = dissimilar to 1 = maximally similar).


"""
from mol_properties import create_tanimoto_groups
from k_fold_partition import create_tanimoto_kfold_partition

first_round_molecules_rdkit, features_first_round_molecules, first_round_molecules_morgan_fingerprints = get_features_and_morgan_fingerprints(table_first_round_molecules)

# evaluation_molecules_morgan_fingerprints = calculate_morgan_fingerprints(evaluation_molecules_rdkit)

# print('Example of descriptors for 10 molecules')
# display(features_first_round_molecules.head())

# Create Tanimoto groups (uses median cutoff adaptively)
print(f"Calculating tanimoto similarities...")
n_groups, groups = create_tanimoto_groups(first_round_molecules_morgan_fingerprints)
print(f"Created {n_groups} groups using tanimoto partition")

# nFirstRoundMols = len(first_round_molecules_rdkit)
# nEvaluationMols = len(evaluation_molecules_rdkit)

# Initialize Tanimoto similarity matrix for first round molecules - similarities between each pair.
# tanimoto_similarities_first_round = np.zeros([nFirstRoundMols,nFirstRoundMols])

# print('Calculating Tanimoto similarities between molecules...')

## Calculate Tanimoto similarities within set of molecules from first round.
# for i in range(nFirstRoundMols):
#   for j in range(i+1,nFirstRoundMols):
#     tanimoto_similarities_first_round[i,j] = calculate_tanimoto_similarity(first_round_molecules_morgan_fingerprints[i],first_round_molecules_morgan_fingerprints[j])
#     tanimoto_similarities_first_round[j,i] = tanimoto_similarities_first_round[i,j]


## Calculate Tanimoto similarities between set of molecules from first round and set from second round.

# Similarities are calculated between "evaluation molecules" (unlabeled, from the second round) and "first round" molecules.
# tanimoto_similarities_evaluation_to_first_round = np.zeros([nEvaluationMols,nFirstRoundMols])
# for i in range(nEvaluationMols):
#   for j in range(nFirstRoundMols):
#     tanimoto_similarities_evaluation_to_first_round[i,j] = calculate_tanimoto_similarity(evaluation_molecules_morgan_fingerprints[i],first_round_molecules_morgan_fingerprints[j])

# print('Done.')

## Explain this code section for Q4/5.

# For each evaluation molecule, find the maximum similarity to any first-round molecule.
# Plot a histogram of these max similarities and select the median as the cutoff (tanimoto_cut_off).

# similarity_to_closest_labeled_molecule = tanimoto_similarities_evaluation_to_first_round.max(axis=1)
# plt.hist(similarity_to_closest_labeled_molecule,bins=100)
# plt.xlabel('Tanimoto similarity')
# plt.show()

# tanimoto_cut_off = np.median(similarity_to_closest_labeled_molecule)
# print(f'Selected Tanimoto similarity Cut-off: {tanimoto_cut_off:.2f}')

# =================== temporary fix without evaluation set: ===================
# tanimoto_cut_off = np.median(tanimoto_similarities_first_round)
# print(f'Selected Tanimoto similarity Cut-off: {tanimoto_cut_off:.2f}')


# Create groups (clusters) of similar molecules based on Tanimoto similarity cut-off.
# binary_similarity_graph = tanimoto_similarities_first_round >= tanimoto_cut_off
# n_groups, groups = connected_components(csgraph=csr_array(binary_similarity_graph), directed=False, return_labels=True)

# print(f'Created {n_groups} groups')


# train_test_split = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=0)
# [(train_and_val_index, test_index)] = train_test_split.split(features_first_round_molecules,table_first_round_molecules['Class_Label'],groups)

## Use this train/val split for training the GNN.
# train_val_split = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=0)
# [(train_index, val_index)] = train_val_split.split(features_first_round_molecules.iloc[train_and_val_index],table_first_round_molecules['Class_Label'].iloc[train_and_val_index],groups[train_and_val_index])


## Use this 5-fold cross-validation for training and evaluating the feature-based model.

# cross_val_split = StratifiedGroupKFold(n_splits=5,shuffle=True,random_state=0)

# cv_indices = list( cross_val_split.split(features_first_round_molecules.iloc[train_and_val_index], table_first_round_molecules['Class_Label'].iloc[train_and_val_index], groups[train_and_val_index]) )

print("Splitting data")

# Create train/test split (80/20) respecting Tanimoto groups
train_test_split = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=0)
[(train_and_val_index, test_index)] = train_test_split.split(
    features_first_round_molecules,
    table_first_round_molecules['Class_Label'],
    groups
)

# 1. Identify which rows in the WHOLE table have missing PAMPA
missing_pampa_mask = table_first_round_molecules['PAMPA'].isna()
indices_missing_pampa = np.where(missing_pampa_mask)[0]

# 2. Find which of these ended up in the train_and_val_index
rows_to_move = np.intersect1d(train_and_val_index, indices_missing_pampa)

if len(rows_to_move) > 0:
    print(f"Deleting {len(rows_to_move)} rows with missing PAMPA from Train and eval.")

    # 3. Remove them from train_and_val_index
    train_and_val_index = np.setdiff1d(train_and_val_index, rows_to_move)

    # 4. Sort indices to keep things tidy
    train_and_val_index.sort()
    test_index.sort()

# Use this train/val split for training the GNN.
train_val_split = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=0)
[(train_index, val_index)] = train_val_split.split(features_first_round_molecules.iloc[train_and_val_index],table_first_round_molecules['Class_Label'].iloc[train_and_val_index],groups[train_and_val_index])

# Create 5-fold cross-validation partition
cv_indices = create_tanimoto_kfold_partition(
    X=features_first_round_molecules,
    y=table_first_round_molecules['Class_Label'].values,
    groups=groups,
    n_splits=5,
    random_state=0
)


"""3.	Justify the choice of threshold used for Tamimoto similarity.

4.	Explain how the algorithm prevents two molecules with high Tamimoto similarity from ending up in the same split.

# Part III: Training a tree ensemble model on the Dataset.

5.	 Throughout the rest of the homework, the metric for model selection and evaluation is chosen to be the Area under the Precision Recall Curve (implemented as the “average_precision_score” in sklearn). Justify this choice of metric given the problem considered.

6.	Using sklearn’s HistGradBoosting (or xgboost/LightGBM), build a Gradient Boosted Tree classifier. Select the optimal hyperparameters (number of iterations; learning rate; regularization strength; number of leaves) by cross-validation using the provided group split. Calculate the precision-recall curve over the test set, display it and report the AUCPR. Comment on the quality of the predictions.
"""

from random_forest import train_and_evaluate_random_forest, analyze_feature_importance

# Train and evaluate Random Forest with 5-fold CV
print("\n" + "="*70)
print("RANDOM FOREST CLASSIFICATION")
print("="*70)

results = train_and_evaluate_random_forest(
    X=features_first_round_molecules,
    y=table_first_round_molecules['Class_Label'],
    cv_indices=cv_indices,
    n_estimators=500,
    class_weight='balanced',
    random_state=0
)

# Analyze feature importance
importance_df = analyze_feature_importance(
    trained_model=results['trained_model'],
    feature_names=features_first_round_molecules.columns,
    top_n=15
)

print("\n" + "="*70)
print("RANDOM FOREST TRAINING COMPLETE")
print("="*70 + "\n")


"""# Part IV: Post-hoc explanations of the tree ensemble model

7.	Using sklearn, calculate the feature importance using the Permutation Feature Importance metric over the train and test set. Which features are the most informative?
"""



"""8.	Using sklearn, display the Partial Dependence Plots (PDP) for the 10 most important features, ordered by importance. Comment on the findings."""



"""9.	Predict the activity of Halicin (SMILE representation: Nc1nnc(Sc2ncc([N+](=O)[O-])s2)s1),  Amoxicilin (SMILE representation: CC1(C)SC2C(NC(=O)C(N)c3ccc(O)cc3)C(=O)N2C1C(=O)O) and calculate the Shapley values associated to these prediction using shap. Are they predicted to be active and why?"""



"""# Part V: Training a Graph Neural Network

To train a GNN, we first create a graph-based representation of each molecule suitable for processing it with GNNs. Here, each node correspond to one heavy atom (excluding hydrogen atoms), and each edge to a covalent bond.

We have per-node features (atom type, etc.) and per-edge features (covalent bond type).  These can be summarized as:

- A node feature matrix $F$, of size Number of atoms by Number of feature nodes.
- An edge feature matrix $F_E$, of size Number of edges by Number of feature nodes.
- An edge indices matrix $E$, of size Number of edges by 2 ($E_{k1},E_{k2}$ are the indices of the incoming and outgoing node for edge k).
"""
"""# Inmplementing a Graph Convolution Network using PyTorch Geometric

This implementation is adapted from https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=0gZ-l0npPIca

I recommend to go over this notebook first.
"""


"""
Step 1: Convert data into PyTorch Geometric Dataset
"""

from CNN import CustomGraphDataset
from torch_geometric.loader import DataLoader

print(f"Building GNN")

first_round_molecules_graph = [molecule_to_graph(mol) for mol in first_round_molecules_rdkit]

# Create the dataset
dataset = CustomGraphDataset(first_round_molecules_graph, table_first_round_molecules['Class_Label'])

train_dataset = dataset[train_index]
validation_dataset = dataset[val_index]
test_dataset = dataset[test_index]


# Create a DataLoader for batching
batch_size = 2
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
evaluation_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

"""
Step 2: Define a simple Graph Convolution Network
Note that here, we don't use the edge features at all
"""
from CNN import GCN

model = GCN(dataset.num_node_features, hidden_channels=64)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
loss_function = torch.nn.L1Loss()

"""# Step 3: Train the model!

*!!! Make sure that you selected the GPU runtype !!* (Runtime -> Change runtime type)
"""

def train():
    model.train()

    for data in train_loader:  # Iterate in batches over the training dataset.
         out = model(data.x, data.edge_attr, data.edge_index, data.batch)  # Perform a single forward pass.
         loss = loss_function(out, data.y)  # Compute the loss.
         loss.backward()  # Derive gradients.
         optimizer.step()  # Update parameters based on gradients.
         optimizer.zero_grad()  # Clear gradients.


def test(loader):
     model.eval()
     total_mae = 0
     total_samples = 0
     for data in loader:  # Iterate in batches over the training/test dataset.
         out = model(data.x, data.edge_attr, data.edge_index, data.batch)
         mae = torch.nn.functional.l1_loss(out.squeeze(), data.y.float(), reduction='sum')  # computes the sum of absolute errors
         total_mae += mae.item()
         total_samples += data.y.size(0)  # Count the number of samples.

     return total_mae / total_samples  # calcualte MAE


for epoch in range(1, 10):  # TODO (ASK): temp until running on GPU
    train()
    train_mae = test(train_loader)
    val_mae = test(validation_loader)
    test_mae = test(test_loader)
    print(f'Epoch: {epoch:03d}, Train MAE: {train_mae:.4f}, Val MAE: {test_mae:.4f},  Test MAE: {test_mae:.4f}')

