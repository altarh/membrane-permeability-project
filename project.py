# -*- coding: utf-8 -*-

"""MLCB Homework 2: Post hoc explanations and Graph Neural Networks .ipynb

Automatically generated by Colab.

Original file is located at
https://colab.research.google.com/drive/175K_tqNhHlc8ZiFXUEqIqbI2vEbPX3A_

# Advanced Topics in Machine Learning for Computational Biology

## Homework 2: Antimicrobial Property prediction with tree ensembles and graph neural networks

Figure and data from: A Deep Learning Approach to Antimicrobial Discovery, Stokes et al. Cell 2020.

## Download data & install packages
"""

# NOT NEEDED - original homework data download
#!wget https://github.com/jertubiana/jertubiana.github.io/raw/master/misc/MLCB_2024_HW2_Data.zip
#!unzip /content/MLCB_2024_HW2_Data.zip
#!pip install matplotlib seaborn shap torch_geometric rdkit

"""# Package & data loading"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy.sparse import csr_array
from scipy.sparse.csgraph import connected_components
from sklearn.model_selection import GroupShuffleSplit, StratifiedGroupKFold

from data_loading import read_file_and_add_Class_Label
from mol_properties import get_features_and_morgan_fingerprints
from mol_to_GNN import molecule_to_graph

try:
    from IPython.display import display
except ImportError:
    def display(obj):
        print(obj)  # Fallback to print

# table_first_round_molecules   =  pd.read_excel( '/content/MLCB_2024_HW2_Data/training_table.xlsx',skiprows=1,sheet_name='S1B')
table_first_round_molecules = read_file_and_add_Class_Label('CycPeptMPDB_Peptide_All.csv')

print(table_first_round_molecules['Class_Label'].iloc[0:5])

print( 'Training table') # This dataset was collected in the first experimental round and will be used for training/evaluating the performance of our model.
display(table_first_round_molecules.head())

# table_evaluation_molecules = pd.read_excel('/content/MLCB_2024_HW2_Data/DrugRepurposing_Hub_predictions.xlsx',skiprows=1,sheet_name='S2B').drop(columns=['Unnamed: 6','Broad_ID'])
# print( 'Evaluation table') # This dataset was used for screening candidates in the second experimental round. We will use it for inference only.
# display(table_evaluation_molecules.head())

"""# Part 0: Parsing the data into Tabular Machine Learning format using the RDKIT package

In this section we:
- Convert each SMILE into a RDKIT Molecule class instance, which has many useful methods.

- Calculate various physio-chemical features for each molecule using RDKIT pre-provided functions. Example of features include number of atoms and bonds of each type, number of hydrogen bond donor and acceptors, etc.

"""

# SMILES is a string-based representation of molecules.
# first_round_molecules_smiles = table_first_round_molecules['SMILES']
# evaluation_molecules_smiles = table_evaluation_molecules['SMILES']

# We first turn each molecule into an instance of the RDKIT molecule.
# first_round_molecules_rdkit = [Chem.MolFromSmiles(smiles) for smiles in first_round_molecules_smiles]
# evaluation_molecules_rdkit = [Chem.MolFromSmiles(smiles) for smiles in evaluation_molecules_smiles]

# Discard examples for which conversion failed.
# first_round_molecules_success = [i for i in range(len(first_round_molecules_rdkit)) if first_round_molecules_rdkit[i] is not None]
# evaluation_molecules_success = [i for i in range(len(evaluation_molecules_rdkit)) if evaluation_molecules_rdkit[i] is not None]

# print(f'Molecule construction suceeded for {len(first_round_molecules_success)}/{len(first_round_molecules_rdkit)} examples in the first round dataset')
# if len(first_round_molecules_success) < len(first_round_molecules_rdkit):
#     print(f'Molecule construction failed for { len(first_round_molecules_rdkit)-len(first_round_molecules_success) }/{len(first_round_molecules_rdkit)} examples in the first round dataset')
# print(f'Molecule construction failed for {len(evaluation_molecules_rdkit) - len(evaluation_molecules_success)}/{len(evaluation_molecules_rdkit)} examples in the evaluation dataset')

# table_first_round_molecules = table_first_round_molecules.iloc[first_round_molecules_success].reset_index()
# table_evaluation_molecules = table_evaluation_molecules.iloc[evaluation_molecules_success].reset_index()

# first_round_molecules_rdkit = [mol for mol in first_round_molecules_rdkit if mol is not None]
# evaluation_molecules_rdkit = [mol for mol in evaluation_molecules_rdkit if mol is not None]


# print('Extracting chemical features/descriptors for each molecule...')
# features_first_round_molecules = extract_chemical_features(first_round_molecules_rdkit)
# print('Done.')
# features_first_round_molecules.index = table_first_round_molecules['Name']

# features_evaluation_molecules = extract_chemical_features(evaluation_molecules_rdkit)
# features_evaluation_molecules.index = table_evaluation_molecules['Name']

"""# Part I: Exploratory Data Analysis

1.	Display, as a scatter plot, the distribution of the number of atoms and covalent bonds per molecule. Color by the measured  class. Is there a relationship between molecule size and activity?
"""



"""2.	For each of the following five features:
*   Octanol-water partition coefficient
*   Molecular weight
*   Number of hydrogen bond donors
*   Number of hydrogen bond acceptors
*   Number of aromatic rings


Display the histogram of the feature value, for each of the two classes. Which feature(s) have the strongest discriminative power?

"""



"""# Part II: Data Partition

Our training data is NOT independently distributed because many known antimicrobial molecules were obtained by small modifications of previously known molecules. Indeed, similar molecules often have similar chemical activity. We thus need to partition the data with grouped splits.


Specifically, our goal is to build a model that can generalize well to unseen molecules. To this end, we want to make sure that our molecules from the train, validation and test are “dissimilar enough”.


We will use the Tanimoto similarity, a custom metric for calculating similarity between molecules (from 0 = dissimilar to 1 = maximally similar).


"""
from mol_properties import create_tanimoto_groups
from k_fold_partition import create_tanimoto_kfold_partition

first_round_molecules_rdkit, features_first_round_molecules, first_round_molecules_morgan_fingerprints = get_features_and_morgan_fingerprints(table_first_round_molecules)

# evaluation_molecules_morgan_fingerprints = calculate_morgan_fingerprints(evaluation_molecules_rdkit)

print('Example of descriptors for 10 molecules')
display(features_first_round_molecules.head())

# Create Tanimoto groups (uses median cutoff adaptively)
groups = create_tanimoto_groups(first_round_molecules_morgan_fingerprints)

# nFirstRoundMols = len(first_round_molecules_rdkit)
# nEvaluationMols = len(evaluation_molecules_rdkit)

# Initialize Tanimoto similarity matrix for first round molecules - similarities between each pair.
# tanimoto_similarities_first_round = np.zeros([nFirstRoundMols,nFirstRoundMols])

# print('Calculating Tanimoto similarities between molecules...')

## Calculate Tanimoto similarities within set of molecules from first round.
# for i in range(nFirstRoundMols):
#   for j in range(i+1,nFirstRoundMols):
#     tanimoto_similarities_first_round[i,j] = calculate_tanimoto_similarity(first_round_molecules_morgan_fingerprints[i],first_round_molecules_morgan_fingerprints[j])
#     tanimoto_similarities_first_round[j,i] = tanimoto_similarities_first_round[i,j]


## Calculate Tanimoto similarities between set of molecules from first round and set from second round.

# Similarities are calculated between "evaluation molecules" (unlabeled, from the second round) and "first round" molecules.
# tanimoto_similarities_evaluation_to_first_round = np.zeros([nEvaluationMols,nFirstRoundMols])
# for i in range(nEvaluationMols):
#   for j in range(nFirstRoundMols):
#     tanimoto_similarities_evaluation_to_first_round[i,j] = calculate_tanimoto_similarity(evaluation_molecules_morgan_fingerprints[i],first_round_molecules_morgan_fingerprints[j])

# print('Done.')

## Explain this code section for Q4/5.

# For each evaluation molecule, find the maximum similarity to any first-round molecule.
# Plot a histogram of these max similarities and select the median as the cutoff (tanimoto_cut_off).

# similarity_to_closest_labeled_molecule = tanimoto_similarities_evaluation_to_first_round.max(axis=1)
# plt.hist(similarity_to_closest_labeled_molecule,bins=100)
# plt.xlabel('Tanimoto similarity')
# plt.show()

# tanimoto_cut_off = np.median(similarity_to_closest_labeled_molecule)
# print(f'Selected Tanimoto similarity Cut-off: {tanimoto_cut_off:.2f}')

# =================== temporary fix without evaluation set: ===================
# tanimoto_cut_off = np.median(tanimoto_similarities_first_round)
# print(f'Selected Tanimoto similarity Cut-off: {tanimoto_cut_off:.2f}')


# Create groups (clusters) of similar molecules based on Tanimoto similarity cut-off.
# binary_similarity_graph = tanimoto_similarities_first_round >= tanimoto_cut_off
# n_groups, groups = connected_components(csgraph=csr_array(binary_similarity_graph), directed=False, return_labels=True)

# print(f'Created {n_groups} groups')


# train_test_split = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=0)
# [(train_and_val_index, test_index)] = train_test_split.split(features_first_round_molecules,table_first_round_molecules['Class_Label'],groups)

## Use this train/val split for training the GNN.
# train_val_split = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=0)
# [(train_index, val_index)] = train_val_split.split(features_first_round_molecules.iloc[train_and_val_index],table_first_round_molecules['Class_Label'].iloc[train_and_val_index],groups[train_and_val_index])


## Use this 5-fold cross-validation for training and evaluating the feature-based model.

# cross_val_split = StratifiedGroupKFold(n_splits=5,shuffle=True,random_state=0)

# cv_indices = list( cross_val_split.split(features_first_round_molecules.iloc[train_and_val_index], table_first_round_molecules['Class_Label'].iloc[train_and_val_index], groups[train_and_val_index]) )


# Create train/test split (80/20) respecting Tanimoto groups
train_test_split = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=0)
[(train_and_val_index, test_index)] = train_test_split.split(
    features_first_round_molecules,
    table_first_round_molecules['Class_Label'],
    groups
)

# 1. Identify which rows in the WHOLE table have missing PAMPA
missing_pampa_mask = table_first_round_molecules['PAMPA'].isna()
indices_missing_pampa = np.where(missing_pampa_mask)[0]

# 2. Find which of these ended up in the train_and_val_index
rows_to_move = np.intersect1d(train_and_val_index, indices_missing_pampa)

if len(rows_to_move) > 0:
    print(f"Moving {len(rows_to_move)} rows with missing PAMPA from Train to Test.")

    # 3. Remove them from train_and_val_index
    train_and_val_index = np.setdiff1d(train_and_val_index, rows_to_move)

    # 4. Add them to test_index
    test_index = np.union1d(test_index, rows_to_move)

    # 5. Sort indices to keep things tidy
    train_and_val_index.sort()
    test_index.sort()

# Create 5-fold cross-validation partition
cv_indices = create_tanimoto_kfold_partition(
    X=features_first_round_molecules,
    y=table_first_round_molecules['Class_Label'].values,
    groups=groups,
    n_splits=5,
    random_state=0
)


"""3.	Justify the choice of threshold used for Tamimoto similarity.

4.	Explain how the algorithm prevents two molecules with high Tamimoto similarity from ending up in the same split.

# Part III: Training a tree ensemble model on the Dataset.

5.	 Throughout the rest of the homework, the metric for model selection and evaluation is chosen to be the Area under the Precision Recall Curve (implemented as the “average_precision_score” in sklearn). Justify this choice of metric given the problem considered.

6.	Using sklearn’s HistGradBoosting (or xgboost/LightGBM), build a Gradient Boosted Tree classifier. Select the optimal hyperparameters (number of iterations; learning rate; regularization strength; number of leaves) by cross-validation using the provided group split. Calculate the precision-recall curve over the test set, display it and report the AUCPR. Comment on the quality of the predictions.
"""

from random_forest import train_and_evaluate_random_forest, analyze_feature_importance

# Train and evaluate Random Forest with 5-fold CV
print("\n" + "="*70)
print("RANDOM FOREST CLASSIFICATION")
print("="*70)

results = train_and_evaluate_random_forest(
    X=features_first_round_molecules,
    y=table_first_round_molecules['Class_Label'],
    cv_indices=cv_indices,
    n_estimators=500,
    class_weight='balanced',
    random_state=0
)

# Analyze feature importance
importance_df = analyze_feature_importance(
    trained_model=results['trained_model'],
    feature_names=features_first_round_molecules.columns,
    top_n=15
)

print("\n" + "="*70)
print("RANDOM FOREST TRAINING COMPLETE")
print("="*70 + "\n")


"""# Part IV: Post-hoc explanations of the tree ensemble model

7.	Using sklearn, calculate the feature importance using the Permutation Feature Importance metric over the train and test set. Which features are the most informative?
"""



"""8.	Using sklearn, display the Partial Dependence Plots (PDP) for the 10 most important features, ordered by importance. Comment on the findings."""



"""9.	Predict the activity of Halicin (SMILE representation: Nc1nnc(Sc2ncc([N+](=O)[O-])s2)s1),  Amoxicilin (SMILE representation: CC1(C)SC2C(NC(=O)C(N)c3ccc(O)cc3)C(=O)N2C1C(=O)O) and calculate the Shapley values associated to these prediction using shap. Are they predicted to be active and why?"""



"""# Part V: Training a Graph Neural Network

To train a GNN, we first create a graph-based representation of each molecule suitable for processing it with GNNs. Here, each node correspond to one heavy atom (excluding hydrogen atoms), and each edge to a covalent bond.

We have per-node features (atom type, etc.) and per-edge features (covalent bond type).  These can be summarized as:

- A node feature matrix $F$, of size Number of atoms by Number of feature nodes.
- An edge feature matrix $F_E$, of size Number of edges by Number of feature nodes.
- An edge indices matrix $E$, of size Number of edges by 2 ($E_{k1},E_{k2}$ are the indices of the incoming and outgoing node for edge k).
"""

first_round_molecules_graph = [molecule_to_graph(mol) for mol in first_round_molecules_rdkit]
# evaluation_molecules_graph = [molecule_to_graph(mol) for mol in evaluation_molecules_rdkit]


print('Example of graph representation for one molecules')

print('Node features shape',first_round_molecules_graph[0][0].shape)
print( first_round_molecules_graph[0][0] )

print('Edge features shape',first_round_molecules_graph[0][1].shape)
print( first_round_molecules_graph[0][1] )


print('Edge indices shape',first_round_molecules_graph[0][2].shape)
print( first_round_molecules_graph[0][2] )

"""# Inmplementing a Graph Convolution Network using PyTorch Geometric

This implementation is adapted from https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=0gZ-l0npPIca

I recommend to go over this notebook first.


## Step 1: Convert data into PyTorch Geometric Dataset
"""

import torch
from torch_geometric.data import Data, Dataset
from torch_geometric.loader import DataLoader


# TODO (ASK): move to mol_to_GNN.py ?
# Custom Dataset class
class CustomGraphDataset(Dataset):
    def __init__(self, graph_triplets, graph_labels=None, transform=None, pre_transform=None):
        super(CustomGraphDataset, self).__init__(transform=transform, pre_transform=pre_transform)
        self.data_list = self._process_examples(graph_triplets,graph_labels=graph_labels)

    def _process_examples(self, graph_triplets,graph_labels=None):
      N = len(graph_triplets)
      data_list = []
      for n in range(N):
          node_features, edge_features, edge_indices = graph_triplets[n]
          label = torch.tensor( graph_labels[n]) if graph_labels is not None else None

          # Create a Data object for each graph
          data = Data(
              x=node_features,               # Node features
              edge_attr=edge_features,       # Edge features
              edge_index=edge_indices.T,       # Edge indices
              y=label                        # Binary label
          )
          data_list.append(data)
      return data_list

    def len(self):
        """
        Return the number of graphs in the dataset.
        """
        return len(self.data_list)

    def get(self, idx):
        """
        Return the Data object at index idx.
        """
        return self.data_list[idx]



# Create the dataset
dataset = CustomGraphDataset(first_round_molecules_graph, table_first_round_molecules['Class_Label'])

train_dataset = dataset[train_index]
validation_dataset = dataset[val_index]
test_dataset = dataset[test_index]

# evaluation_dataset = CustomGraphDataset(evaluation_molecules_graph)


# Create a DataLoader for batching
batch_size = 2
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
evaluation_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

"""## Step 2: Define a simple Graph Convolution Network
Note that here, we don't use the edge features at all.**bold text**
"""

from torch.nn import Linear
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.nn import global_mean_pool


class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super(GCN, self).__init__()
        torch.manual_seed(12345)


        # Initialize the layers
        self.node_embedding = Linear(dataset.num_node_features, hidden_channels)
        self.conv = GCNConv(hidden_channels, hidden_channels)
        self.lin = Linear(hidden_channels, 2) # Here, only two classes


    def forward(self, node_features, edge_features, edge_index, batch):

        # 1. Embed node features
        x = self.node_embedding(node_features)
        x = x.relu()

        # 2. Pass through a [permutation-equivariant] GCN layer

        x = self.conv(x, edge_index) # Element-wise non-linearity
        x = x.relu() # Element-wise non-linearity

        # 3. Global average pooling for obtaining a permutation-invariant representation.
        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]

        # 4. Apply a final classifier
        x = self.lin(x) # This is the pre-sigmoid output.
        return x



model = GCN(hidden_channels=64)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
loss_function = torch.nn.CrossEntropyLoss()

"""# Step 3: Train the model!

*!!! Make sure that you selected the GPU runtype !!* (Runtime -> Change runtime type)
"""

def train():
    model.train()

    for data in train_loader:  # Iterate in batches over the training dataset.
         out = model(data.x, data.edge_attr, data.edge_index, data.batch)  # Perform a single forward pass.
         loss = loss_function(out, data.y)  # Compute the loss.
         loss.backward()  # Derive gradients.
         optimizer.step()  # Update parameters based on gradients.
         optimizer.zero_grad()  # Clear gradients.

def test(loader):
     model.eval()
     correct = 0
     for data in loader:  # Iterate in batches over the training/test dataset.
         out = model(data.x, data.edge_attr, data.edge_index, data.batch)
         pred = out.argmax(dim=1)  # Most likely output.
         correct += int((pred == data.y).sum())  # Check against ground-truth labels.
     return correct / len(loader.dataset)  # Derive ratio of correct predictions.


for epoch in range(1, 10):  # TODO (ASK): temp until running on GPU
    train()
    train_acc = test(train_loader)
    val_acc = test(validation_loader)
    test_acc = test(test_loader)
    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Val Acc: {test_acc:.4f} ,  Test Acc: {test_acc:.4f}')

"""11.	Setting the number of epochs and early stopping.


a.	Modify the code to record the Area Under the Precision Recall Curve (AUCPR) over the train and validation set after each epoch and plot the learning curve (metric vs epoch) for the train and validation set. Adjust the number of epochs until overfitting is observed.

b.	Retrain the same GCN model, but add an early stopping criterion using the AUCPR calculated over the validation set. Report the performance on the test set. How does it compare to the feature-based model?

"""



"""12.	How many parameters does the GCN have, as function of the number of layers and of the dimension of the node features?

13.	Varying the network width: Train GCNs with varying node feature dimensions ([16,32,64,128] ) and plot the learning curves of the model (loss vs number of epochs) on the training and validation sets. Are there signs of overfitting? Why?
"""



"""14.	Varying the network depth and the oversmoothing effect: Train GCNs with varying number of layers ([1, 3,5,10]), and (approximately) fixed number of parameters, and plot the learning curves of the model. Are there signs of overfitting? Underfitting? Why?

15.	Virtual screening: Pick the best GNN, and use it to predict antimicrobial activity on the evaluation set. How do the predictions correlate with the ones of the D-MPNN model? Does it predict halicin to have an activity?
"""



"""Bonus: So far, we did not use at all the edge features (i.e., whether a chemical bond is a simple, double, aromatic bond, etc.). Build a Message-Passing Neural Network that integrate these features and compare the performance of the model with the one of the GCN."""

